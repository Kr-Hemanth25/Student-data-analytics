{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Student CSV Analysis\n",
        "\n",
        "Use this notebook to interactively analyze a students CSV and reproduce the stats and charts used in the app.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "csv_path = Path('../data/students_synthetic_500.csv')\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overview stats\n",
        "numeric_cols = [c for c in ['comprehension','attention','focus','retention','engagement_time','assessment_score'] if c in df.columns]\n",
        "df[numeric_cols].mean(numeric_only=True).round(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlations with assessment_score\n",
        "corr = df.corr(numeric_only=True)\n",
        "corr['assessment_score'].sort_values(ascending=False).round(3) if 'assessment_score' in corr.columns else corr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Persona buckets derived from assessment scores (if model unavailable)\n",
        "def persona_from_score(score: float) -> str:\n",
        "    if score >= 85: return 'High Performer'\n",
        "    if score >= 70: return 'Consistent Learner'\n",
        "    if score >= 50: return 'Developing Learner'\n",
        "    return 'Needs Support'\n",
        "\n",
        "personas = df['assessment_score'].apply(persona_from_score) if 'assessment_score' in df.columns else None\n",
        "personas.value_counts() if personas is not None else 'assessment_score not present'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score distribution (10-point bins)\n",
        "import pandas as pd\n",
        "bins = list(range(0, 101, 10))\n",
        "labels = [f\"{b}-{b+10 if b<90 else 100}\" for b in bins[:-1]]\n",
        "dist = pd.cut(df['assessment_score'], bins=bins, include_lowest=True, labels=labels).value_counts().sort_index()\n",
        "dist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Source: analyze_csv.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contents of analyze_csv.py\n",
        "import sys\n",
        "import json\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from sklearn.cluster import KMeans\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    import joblib\n",
        "except Exception:\n",
        "    KMeans = None\n",
        "    LinearRegression = None\n",
        "    joblib = None\n",
        "\n",
        "\n",
        "def compute_overview(df: pd.DataFrame):\n",
        "    numeric_cols = [c for c in [\n",
        "        'comprehension','attention','focus','retention','engagement_time','assessment_score'\n",
        "    ] if c in df.columns]\n",
        "    stats = df[numeric_cols].mean(numeric_only=True).to_dict()\n",
        "    return { k: float(round(v,2)) for k,v in stats.items() }\n",
        "\n",
        "\n",
        "def compute_correlations(df: pd.DataFrame):\n",
        "    corr = df.corr(numeric_only=True)\n",
        "    if 'assessment_score' in corr.columns:\n",
        "        series = corr['assessment_score'].sort_values(ascending=False)\n",
        "        return { k: float(round(v,3)) for k,v in series.items() }\n",
        "    return {}\n",
        "\n",
        "\n",
        "def predict_scores(df: pd.DataFrame):\n",
        "    model_path = Path(__file__).resolve().parent / 'student_score_model.pkl'\n",
        "    if joblib is None or not model_path.exists():\n",
        "        return None\n",
        "    model = joblib.load(model_path)\n",
        "    needed = ['comprehension','attention','focus','retention','engagement_time']\n",
        "    if not all(c in df.columns for c in needed):\n",
        "        return None\n",
        "    X = df[needed].astype(float).values\n",
        "    preds = model.predict(X)\n",
        "    return [ float(round(p,2)) for p in preds ]\n",
        "\n",
        "\n",
        "def persona_from_score(score: float) -> str:\n",
        "    if score >= 85: return 'High Performer'\n",
        "    if score >= 70: return 'Consistent Learner'\n",
        "    if score >= 50: return 'Developing Learner'\n",
        "    return 'Needs Support'\n",
        "\n",
        "\n",
        "def cluster_personas(df: pd.DataFrame):\n",
        "    # If model predictions available, use them to label; else kmeans\n",
        "    preds = predict_scores(df)\n",
        "    personas = []\n",
        "    if preds is not None:\n",
        "        personas = [ persona_from_score(p) for p in preds ]\n",
        "    else:\n",
        "        if KMeans is None:\n",
        "            return None\n",
        "        needed = ['comprehension','attention','focus','retention','engagement_time']\n",
        "        if not all(c in df.columns for c in needed):\n",
        "            return None\n",
        "        X = df[needed].astype(float).values\n",
        "        km = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "        labels = km.fit_predict(X)\n",
        "        mapping = {0:'High Performer',1:'Consistent Learner',2:'Developing Learner'}\n",
        "        personas = [ mapping.get(int(l), 'Persona') for l in labels ]\n",
        "    return personas\n",
        "\n",
        "\n",
        "def main():\n",
        "    raw = sys.stdin.buffer.read()\n",
        "    if not raw:\n",
        "        print(json.dumps({\"error\":\"no_input\"}))\n",
        "        return\n",
        "    try:\n",
        "        text = raw.decode('utf-8', errors='ignore')\n",
        "        df = pd.read_csv(io.StringIO(text))\n",
        "    except Exception as e:\n",
        "        print(json.dumps({\"error\": f\"csv_parse_failed: {e}\"}))\n",
        "        return\n",
        "\n",
        "    overview = compute_overview(df)\n",
        "    correlations = compute_correlations(df)\n",
        "    personas = cluster_personas(df)\n",
        "\n",
        "    result = {\n",
        "        \"overview\": overview,\n",
        "        \"correlations\": correlations,\n",
        "        \"personas\": personas,\n",
        "        \"count\": int(len(df)),\n",
        "        \"columns\": list(df.columns),\n",
        "        \"preview\": df.to_dict(orient='records')\n",
        "    }\n",
        "    print(json.dumps(result))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Source: predict.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contents of predict.py\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import joblib\n",
        "except Exception as e:\n",
        "    print(json.dumps({\"error\": \"joblib not installed\"}))\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "def load_model(model_path: Path):\n",
        "    if not model_path.exists():\n",
        "        raise FileNotFoundError(f\"Model not found at {model_path}\")\n",
        "    return joblib.load(model_path)\n",
        "\n",
        "\n",
        "def read_input():\n",
        "    try:\n",
        "        data = json.loads(sys.stdin.read() or \"{}\")\n",
        "        return data\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "\n",
        "def to_features(payload: dict):\n",
        "    keys = [\"comprehension\", \"attention\", \"focus\", \"retention\", \"engagement_time\"]\n",
        "    values = []\n",
        "    for k in keys:\n",
        "        v = payload.get(k, 0)\n",
        "        try:\n",
        "            v = float(v)\n",
        "        except Exception:\n",
        "            v = 0.0\n",
        "        values.append(v)\n",
        "    return np.array(values, dtype=float).reshape(1, -1)\n",
        "\n",
        "\n",
        "def persona_from_score(score: float) -> str:\n",
        "    if score >= 85:\n",
        "        return \"High Performer\"\n",
        "    if score >= 70:\n",
        "        return \"Consistent Learner\"\n",
        "    if score >= 50:\n",
        "        return \"Developing Learner\"\n",
        "    return \"Needs Support\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    # model path relative to this script\n",
        "    model_path = Path(__file__).resolve().parent / \"student_score_model.pkl\"\n",
        "    try:\n",
        "        model = load_model(model_path)\n",
        "    except Exception as e:\n",
        "        print(json.dumps({\"error\": str(e)}))\n",
        "        return\n",
        "\n",
        "    payload = read_input()\n",
        "    X = to_features(payload)\n",
        "    try:\n",
        "        y_pred = float(model.predict(X)[0])\n",
        "    except Exception as e:\n",
        "        print(json.dumps({\"error\": f\"prediction_failed: {e}\"}))\n",
        "        return\n",
        "\n",
        "    result = {\n",
        "        \"score\": round(y_pred, 2),\n",
        "        \"persona\": persona_from_score(y_pred),\n",
        "    }\n",
        "    print(json.dumps(result))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
